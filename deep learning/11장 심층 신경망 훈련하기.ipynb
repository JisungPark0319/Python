{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11장 심층 신경망 훈련하기.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZOUmYl8wrY3VSMsZI6iky"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QErL1ZLexBE2","colab_type":"text"},"source":["그레이디언트 소실과 폭주\n","\n","그레이디언트 소실(Vanishing gradient)\n"," - 하위층으로 진행될수록 그레이디언트가 점점 작아지는 현상\n"," - 하위층의 연결 가중치를 변경되지 않은 채로 둔다면 훈련이 좋은 솔루션으로 \n","   수렴되기 어렵다\n","\n","그레이디언트 폭주(Exploding gradient)\n"," - 소실과 반대로 그레이디언트가 점점 증가하는 현상\n","\n","소실과 폭주를 막기위한 초기화 방식\n"," - 글로럿 :  활성화 함수없음, 하이퍼볼릭 탄젠트, 로지스틱, 소프트맥스 ( 1 / fan.avg )\n"," - He : ReLU 함수와 그 변종들 ( 2 / fan.in )\n"," - 르쿤 : SELU ( 1 / fan.in )\n"," - 케라스는 기본적으로 균등분포의 글로럿 초기화 방식 사용\n","\n","ReLU 함수의 변종\n"," - 훈련 중 가중치 합이 음수이면 ReLU 함수의 그레이디언트가 0이 되므로 경사 하강법이 더는 작동하지 않는다.\n"," - ReLU가 죽는 현상을 막기위해 변종된 ReLU함수가 등장\n","  1. LeakyReLU\n","    - LeakyRelu.a(z)=max(az, z)로 정의\n","    - 하이퍼파라미터 a가 새는(leaky)정도를 결정\n","    - 새는 정도란 z < 0 일 때 이 함수의 기울기이며, 일반적으로 0.01로 설정\n","    - a=0.2로 하는 것이 a=0.1보다 더 나은 성능을 나타낸다\n","  2. RReLU(Randomized leaky ReLU)\n","    - 훈련하는 동안 주어진 범위에서 a를 무작위로 선택하고 테스트 시에는 평균을 사용\n","    - 훈련 세트의 과대적합 위험을 줄이는 규제 역할도 한다\n","  3. PReLU(Parametric leaky ReLU)\n","    - a가 훈련하는 동안 학습\n","    - 대규모 이미지 데이터셋에서는 ReLU보다 성능이 크게 앞섰지만, 소규모 데이터셋에서는 훈련 세트에 과대적합될 위험이 있다\n","\n","ELU(Exponential linear unit)\n"," - ELU.a(z) = z < 0 일 때 a(exp(z)-1) , z >= 0 일 때 z\n"," - z < 0일 때 활성화 함수의 ㅎ평균 출력이 0에 더 가까워져 그레이디언트 손실문제를 완하시켜준다.\n"," - 하이퍼파라미터 a는 z가 큰 음숫값일 때 ELU가 수렴할 값을 정의\n"," - z < 0 이어도 그레이디언트가 0이 아니므로 죽는 뉴런은 안 만들어진다.\n"," - a = 1이면 z = 0에서 급격히 변동하지 않아 모든 구간에서 매끄러워 경사하강법의 속도를 높여준다\n"," - 지수 함수를 사용하므로 계산이 느리다\n","\n","SELU(Scaled ELU)\n"," - 스케일이 조정된 ELU 활성화 함수의 변종\n"," - 신경망을 만들고 모든 은닉층이 SELU 활성화 함수를  사용하며 네트워크가 자기 정규화가 된다.\n"," - 훈련하는 동안 각 층의 출력이 평균 0과 표준편타 1을 유지해 그레이디언트 소실과 폭주 문제를 막아준다.\n"," - 자기 정규화 일어나는 조건\n","   1. 입력 특성이 반드시 표준화되어야 한다.\n","   2. 모든 은닉층의 가중치는 르쿤 정규분포 초기화로 초기화\n","   3. 네트워크는 일렬로 쌓은 층으로 구성\n","\n","심층 신경망에는 일반적으로 SELU > ELU > LeakyReLU(그외 변종) > ReLU > tanh > 로지스틱 순으로 사용\n"," \n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y0HgbCUPctk7","colab_type":"text"},"source":["배치 정규화(Batch normalization)\n"," - 그레이디언트 손실과 폭주 문제를 해결하기위한 기법\n"," - 각 층에서 활성화 함수를 통과하기 전이나, 후에 모델에 연산을 추가\n"," - 연산은 입력을 원점에 맞추고 정규화한 다음, 각 층에서 두 개의 새로운 파라미터로 결과값의 스케일을 조정하고 이동\n"," - 파라미터는 스케일 조정과 이동에 사용\n"," - 신경망의 첫 번째 층으로 배치 정규화를 추가하면 훈련 세트의 표준화가 필요 없음\n"," - 훈련하는 동안 배치 정규화는 입력을 정규화한 다음 스케일 조정하고 이동시킨다.\n"," - 훈련이 끝난 후 전체 훈련 세트를 신경망에 통과시켜 배치 정규화층의 각 입력에 대한 평균과 표준 편차를 계산\n"," - 예측할 때 배치 입력 평균과 표준편차로 최종 입력 평균과 표준편차 대신 사용\n"," - 층의 입력 평균과 표준편차의 이동 평균을 사용해 훈련하는 동안 최종 통계를 추정\n"," - 가중치 초기화에 네트워크가 덜 민감해진다.\n"," - 큰 학습률을 사용하여 학습과정의 속도를 높일 수 있다.\n"," - 배치 정규화는 모델의 복잡도를 키워 실행 시간면에서 손해가 나고 신경만의 예측을 느리게 한다.\n"," - 훈련이 끝난 후에 이전 층과 배치 정규화 층을 합쳐 실행속도 저하를 막을 수 있다.\n"]},{"cell_type":"code","metadata":{"id":"jjQml26deJ5D","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwQhD0DpeJ99","colab_type":"code","colab":{}},"source":["model = keras.models.Sequential([\n","                                 keras.layers.Flatten(input_shape=[28, 28]),\n","                                 keras.layers.BatchNormalization(),\n","                                 keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n","                                 keras.layers.BatchNormalization(),\n","                                 keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n","                                 keras.layers.BatchNormalization(),\n","                                 keras.layers.Dense(10, activation=\"softmax\")\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"maCwSeXWeKG0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":413},"executionInfo":{"status":"ok","timestamp":1597673257410,"user_tz":-540,"elapsed":2644,"user":{"displayName":"박지성","photoUrl":"","userId":"00566369760842137872"}},"outputId":"2306fe8c-48a0-4cdf-8b4b-0be1a12282f5"},"source":["model.summary()\n","\n","# non-trainable params : 역전파로 학습되지 않는 파라미터 수 (평균과 표준편차 파라미터)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 784)               0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 784)               3136      \n","_________________________________________________________________\n","dense (Dense)                (None, 300)               235500    \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 300)               1200      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 100)               30100     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 100)               400       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1010      \n","=================================================================\n","Total params: 271,346\n","Trainable params: 268,978\n","Non-trainable params: 2,368\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b1-jWBjeeKDc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1597673257410,"user_tz":-540,"elapsed":2639,"user":{"displayName":"박지성","photoUrl":"","userId":"00566369760842137872"}},"outputId":"191ff808-20a7-46df-b053-bf724c0a80e0"},"source":["[(var.name, var.trainable) for var in model.layers[1].variables] \n","# 두 개는 역전파로 훈련되고 두개는 훈련되지 않았다"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('batch_normalization/gamma:0', True),\n"," ('batch_normalization/beta:0', True),\n"," ('batch_normalization/moving_mean:0', False),\n"," ('batch_normalization/moving_variance:0', False)]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"jQmRDW83eJ69","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1597673257411,"user_tz":-540,"elapsed":2635,"user":{"displayName":"박지성","photoUrl":"","userId":"00566369760842137872"}},"outputId":"aac6cc56-9058-4998-8d25-510dc646fd13"},"source":["# 훈련하는 중 매 반복마다 케라스에서 호출될 두 개의 연산이 함께 생성\n","# 이 연산이 이동 평균을 업데이트\n","# 텐서플로 백엔드를 사용하므로 이 연산은 텐서플로 연산입니다\n","model.layers[1].updates"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-5-2c7e53edf444>:4: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"fYKfR0l2duKA","colab_type":"code","colab":{}},"source":["# 활성화 함수 전에 배치 정규화 층을 추가하려면 은닉층에서 호라성화 함수를 지정하지 말고 배치 정규화 층 뒤에 별도의 층으로 추가\n","# 배치 정규화 층은 입력마다 이동 파라미터를 포함하기 때문에 이전 층에서 편향을 뺄 수 있다.(use_bias=False)\n","model = keras.models.Sequential([\n","                                 keras.layers.Flatten(input_shape=[28, 28]),\n","                                 keras.layers.BatchNormalization(),\n","                                 keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n","                                 keras.layers.BatchNormalization(),\n","                                 keras.layers.Activation(\"elu\"),\n","                                 keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n","                                 keras.layers.BatchNormalization(),\n","                                 keras.layers.Activation(\"elu\"),\n","                                 keras.layers.Dense(10, activation=\"softmax\")\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KS0m1uEPx1BH","colab_type":"text"},"source":["그레이디언트 클리핑\n"," - 그레이디언트 폭주 문제를 완하하는 방법\n"," - 역전파될 때 일정 임곗값을 넘어서지 못하게 그레이디언트를 잘라내는 방식\n"," - 그레이디언트 벡터의 모든 원소를 -1.0과 1.0  사이로 클리핑\n"," - 손실의 모든 편미분 값을 -1.0에서 1.0으로 잘라낸다"]},{"cell_type":"code","metadata":{"id":"tJUnYolEwdWj","colab_type":"code","colab":{}},"source":["# 케라스에서 그레이디언트 클리핑 구현\n","# optimizer 생성 시 clipvalue와 clipnorm 매개변수를 지정\n","optimizer = keras.optimizers.SGD(clipvalue=1.0)\n","model.compile(loss=\"mse\", optimizer=optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPqYTyFlzO2f","colab_type":"text"},"source":["사전훈련된 층 재사용하기\n"," - 전이 학습(transfer learning) : 해결 하려는 것과 비슷한 유형의 문제를 처리한 신경망이 있으면 그 신경망의 하위층을 재사용\n"," - 이 방법은 훈련 속도를 크게 높이고 필요한 훈련 데이터도 크게 줄인다.\n"," - 먼저 재사용하는 층은 모두 동결한다.(SGD로 가중치가 바뀌지 않도록 훈련되지 않는 가중치로 만든다.)\n"," - 모델을 훈련하고 성능을 평가\n"," - 맨 위에 있는 한두개의 은닉층의 동결을 해제하고 역전파를 통해 가중치를 조정하여 성능 확인\n"," - 훈련 데이터가 많은수록 많은 층의 동결을 해제할 수 있다.\n"," - 재사용 층의 동결을 해제 시 학습률을 작게한다.\n"," - 성능이 낮고 훈련 데이터가 적다면 상위 은닉층(들)을 제거하고 남은 은닉층을 다시 동결\n"," - 재사용할 은닉층의 적절한 개수를 찾을때 까지 반복"]},{"cell_type":"code","metadata":{"id":"idVysyV1wdam","colab_type":"code","colab":{}},"source":["# model_A와 model_B_on_A는 일부 층을 공유\n","# model_A_on_B 훈련 시 model_A도 영향을 받는다\n","model_A = keras.models.load_model(\"my_model_A.h5\")\n","model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n","model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n","\n","# 영향 받는 거를 원치 않을 시 model_A를 클론하여 사용\n","model_A_clone = keras.models.clone_model(model_A)\n","model_A_clone.set_weights(model_A.get_weights())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KPawQS2wd5B","colab_type":"code","colab":{}},"source":["# 새로운 출력층이 랜덤하게 초기화되어 있으므로 큰 오차를 만들 것이다\n","# 피하기 위해 처음 몇번의 에포크 동안 재사용된 층을 동결하고 새로운 층에게 적절한 가중치를 학습할 시간을 준다\n","# 모든 층의 trainalbe 속성을 False로 지정하고 컴파일\n","for layer in model_B_on_A.layers[:-1]:\n","  layer.trainable = False\n","\n","model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n","                     metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQwTcE0Fwd82","colab_type":"code","colab":{}},"source":["# 재사용된 층의 동결을 해제하고 훈련\n","# 일반적으로 재사용된 층의 동결을 해제한 후에 학습률을 낮추는 것이 좋다\n","history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))\n","\n","for layer in model_B_on_A.layers[:-1]:\n","  layer.trainable = False\n","\n","optimizer = keras.optimizers.SGD(lr=1e-4) # 기본 학습률 1e-2\n","model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhR_vpKMweAX","colab_type":"code","colab":{}},"source":["model_A_on_B.evaluate(X_text_B, y_text_B)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8K6c20eJKP4","colab_type":"text"},"source":["고속 옵티마이저"]},{"cell_type":"code","metadata":{"id":"jibpOQyzweBt","colab_type":"code","colab":{}},"source":["# 모멘텀 최적화\n","# 이전 그레이디언트가 얼마였는지를 중요하게 여김\n","# 매 반복에서 현재 그레이디언트를(학습률 곱한 후) 모멘텀 벡터m에 더하고 이 값을 빼는 방식으로 가중치를 갱신\n","# 모멘텀 하이퍼파라미터b는 0~1사이의 값을 갖고 기본적으로 0.9를 사용\n","# 지역 최적점을 건너뛰도록 하는데 도움\n","optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wx8CN267wd-n","colab_type":"code","colab":{}},"source":["# 네스테로프 가속 경사(Nesterov accelerated gradient)\n","# 모멘텀의 현재 위치에서 +bm만큼 이동시켜 그레이디언트를 계산\n","# 이동으로 인해 네스테로프 업데이가 최적값에 더 가깝다.\n","optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E29HgeGY4_D2","colab_type":"code","colab":{}},"source":["# AdaGrad\n","# 가장 가파른 차원을 따라 그레이디엉ㄴ트 벡터의 스케일을 감소시키는 방식\n","# 학습률을 감소시키지만 경사가 완만한 차원보다 가파른 차원에 대해 더 빠르게 감소하고 이를 적응적 학습률이라 부른다.\n","# 간단한 2차 방정식에서 잘 작동하지만 신경망 훈련 시 너무 일직 멈추는 경우가 발생\n","# 심층 신경망에서는 사용을 안하는 것이 좋다"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLMGSpm64_Bd","colab_type":"code","colab":{}},"source":["# RMSProp\n","# AdaGrad의 문제점을 훈련 시작부터의 모든 그레이디언트가 아닌 가장 최근 반복에서 비롯된 그레이디언트만 누적함으로서 해결\n","# 하이퍼파라미터 감쇠율이 추가되었고 기본값으로 0.9를 사용한다\n","optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJclbHtqwd7G","colab_type":"code","colab":{}},"source":["# Adam\n","# 적응적 모멘트 추정(Adaptive moment estimation)\n","# 모멘텀 최적화와 RMSProp의 아이디어를 합친 것\n","# 모멘텀 최적화처럼 지난 그레이디언트의 지수 감소 평균을 따르고 \n","# RMSProp처럼 지난 그레이디언트 제곱의 지수 감소된 평균을 따른다.\n","# 모멘텀 감쇠 하이퍼파라미터 b1은 보통 0.9로 초기화,\n","# 스케일 감쇠 하이퍼파라미터 b2는 0.999,\n","# 안정된 계산을 위한 e는 보통 10e-7같은 아주 작은수로 초기화\n","optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sp-pBJgOwdg_","colab_type":"code","colab":{}},"source":["# AdaMax\n","# Adam의 L2노름을 L무한 노름으로 바꾼다\n","# AdaMax가 Adam보다 더 안정적이지만 실제로  데이터셋에 따라 다르다\n","\n","# Nadam\n","# Adam 옵티마이저에 네스테로프 기법을 더한 것\n","# 종종 Adam보다 빠르게 수렴"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TOI_g4AiIj7C","colab_type":"text"},"source":["학습률 스케쥴링\n"," - 훈련하는 동안 학습률을 감소시키는 전략\n"," - 학습률을 너무 크게 잡으면 훈련이 실제로 발산한다.\n"," - 너무 작게 잡으면 최적점에 수렴하지만 시간이 매우 오래걸린다.\n"," - 조금 높게 잡으면 처음에는 매우 빠르게 진행하지만 최적점 근처에서는 요동이 심해져 수렴하지 못한다.\n"," - 간단한 방법으로는 매우 작은 값에서 매우 큰 값까지 지수적으로 학습률을 증가시키면서 모델 훈련을 수백 번 반복하여 좋은 학습률을 찾는 방법\n"," - 또는 큰 학습률로 시작하고 학습 속도가 느려질 때 학습률을 낮추면 최적의 고정 학습률보다 좋은 솔루션을 더 빨리 발견할 수 있다."]},{"cell_type":"code","metadata":{"id":"YlzSqP55wde-","colab_type":"code","colab":{}},"source":["# 거듭제곱 기반 스케줄링(Power Scheduling)\n","# decay 매개변수만 지정\n","# decay는 s(학습률을 나누기 위해 수행할 스텝 수)의 역수\n","optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCk3NTKlwdYp","colab_type":"code","colab":{}},"source":["# 지수 기반 스케줄링(Exponential Scheduling)\n","\n","def exponential_decay(lr0, s):\n","  def exponential_decay_fn(epoch):\n","    return lr0 * 0.1**(epoch / s)\n","  return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n","\n","lr_shceduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n","history = model.fit(X_train_scaled, y_train, [...], callbacks=[lr_scheduler])\n","\n","# 스케줄 중에 하나를 사용해 학습률을  정희하고 이 학습률을 옵티마이저에 전달\n","# 해당 방법으로 구현 시 에포크가 아니라 매 스텝마다 학습률을 업데이트\n","s = 20 * len(X_train) // 32 # 20번 에포크에 담긴 전체 스텝 수(배치크기 = 32)\n","learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n","optimizer = keras.optimizers.SGD(learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P7iv1M_LJLoT","colab_type":"code","colab":{}},"source":["# 구간별 고정 스케줄링(Piecewise Constant Scheduling)\n","def piecewise_constant_fn(epoch):\n","  if epoch < 5:\n","    return 0.01\n","  elif epoch < 15:\n","    return 0.005\n","  elif:\n","    return 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSV50aOaJLth","colab_type":"code","colab":{}},"source":["# 성능 기반 스케줄링(Performance Scheduling)\n","lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUfZNkN_JLqX","colab_type":"code","colab":{}},"source":["# 1사이클 스케줄링(1cycle Scheduling)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MItDaopULyI8","colab_type":"text"},"source":["규제를 사용해 과대적합 피하기"]},{"cell_type":"code","metadata":{"id":"VMamNWTTJLUB","colab_type":"code","colab":{}},"source":["# L1과 L2 규제\n","# 신경망의 연결 가중치를 제한하기 위해 L2 규제를 사용하거나\n","# 희소 모델을 만들기 위해 L1 규제를 사용할 수 있다.\n","\n","# 연결 가중치에 규제강도 0.01을 사용하여 L2 규제 적용\n","layer = keras.layers.Dense(100, activation=\"elu\",\n","                           kernel_initializer=\"he_normal\",\n","                           kernel_regularizer=keras.regularizers.l2(0.01))\n","\n","\n","# 동일한 활성화 함수, 초기화 전략이나 동일한 규제로 매개변수 값을 반복하는 경우 \n","# 파이썬의 functools.partial() 함수를 사용하여 기본 매개변수 값을 사용\n","from functools import partial\n","\n","RegularizedDense = partial(keras.layers.Dense,\n","                           activation=\"elu\",\n","                           kernel_initializer=\"he_normal\",\n","                           kernel_regularizer=keras.regularizers.l2(0.01))\n","\n","model = keras.models.Sequentia([\n","                                keras.layers.Flatten(input_shape=[28,28]),\n","                                RegularizedDense(300),\n","                                RegularizedDense(100),\n","                                RegularizedDense(10, activation=\"softmax\",\n","                                                 kernel_initializer=\"glorot_uniform\")\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SswZSYeNVZe","colab_type":"code","colab":{}},"source":["# 드롭아웃\n","# 매 훈련 습텝에서 각 뉴런은 임시적으로 드롭아웃될 확률 p를 가진다.\n","# 이번 훈련 스텝에는 완전히 무시되지만 다음 스템에는 활성화될 수 있다.\n","# 하이퍼파라미터 p를 드롭아웃 비율이라고하고 보통 10~50% 사이를 지정\n","# 훈련이 끝난 후에는 뉴런에 드롭아웃을 적용하지 않는다.\n","# 테스트하는 동안에는 하나의 뉴런이 훈련 때보다 (평균적으로) 두 배 많은\n","# 입력 뉴런과 연결된다.\n","# 훈련이 끝난 뒤 각 입력의 연결 가중치에 보존확률(1-p)를 곱해야 한다.\n","model = keras.models.Sequential([\n","                                 keras.layers.Flatten(input_shape=[28, 28]),\n","                                 keras.layers.Dropout(rate=0.2),\n","                                 keras.layers.Dense(300, activation=\"elu\",\n","                                                    kernel_initializer=\"he_normal\"),\n","                                 keras.layers.Droupout(rate=0.2),\n","                                 keras.layers.Dense(100, activation=\"elu\",\n","                                                    kernel_initializer=\"he_normal\"),\n","                                 keras.layers.Dropout(rate=0.2),\n","                                 keras.layers.Dense(10, activation=\"softmax\"))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAd-2RTxNVdH","colab_type":"code","colab":{}},"source":["# 몬테 카를로 드롭아웃\n","# 드롭아웃 네트워크와 근사 베이즈 추론 사이에 깊은 고나련성을 정립\n","# 훈련된 드롭아웃 모델을 재훈련하거나 전혀 수정하지 않고 성능을 크게 향상 시킬수 있다.\n","\n","# training=True로 지정하여 Droupout 층을 활성화하고 테스트 세트에서 100번의 예측을 만들어 쌓는다.\n","y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)])\n","y_proba = y_probas.mean(axis=0)\n","\n","# 모델이 훈련하는 동안 다르게 작동하는(BatchNormalization층과 같은) 층을 가지고 있다면\n","# 앞에서와 같이 훈련 모드를 강제로 설정해서는 안된다.\n","# 대신 Droupout층을 다음과 같은 MCDropout 클래스로 바꿔준다.\n","\n","class MCDropout(keras.layers.Dropout):\n","  def call(self, inputs):\n","    return super().call(inputs, training=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cupl5-HrNVXO","colab_type":"code","colab":{}},"source":["# 맥스-노름 규제\n","# 각각의 뉴런에 대해 입력의 연결 가중치 W가 L2노름(W) <= r(맥스-노름 하이퍼파라미터)\n","# 매 훈련 스텝이 끝나고 L2(W)를 계산하고 필요하면 W의 스케일 조정\n","# r을 줄이면 규제의 양이 증가하여 과대적합을 감소시키는데 도움된다.\n","# 불안정한 그레이디언트 문제를 완하하는데 도움을 준다.\n","\n","keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n","                   kernel_constraint=keras.constraints.max_norm(1.)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzNyX4xTJLSM","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}